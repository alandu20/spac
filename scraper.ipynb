{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "from edgar import Company\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_to_cik():\n",
    "    # local copy: data/ticker_to_cik.txt\n",
    "    ticker_to_cik = pd.read_csv('https://www.sec.gov/include/ticker.txt',\n",
    "                                sep='\\t', header=None, names=['ticker','cik'])\n",
    "    ticker_to_cik['ticker'] = ticker_to_cik.ticker.str.upper()\n",
    "    ticker_to_cik['cik'] = ticker_to_cik.cik.astype(str)\n",
    "    return ticker_to_cik\n",
    "\n",
    "def get_cik_to_name():\n",
    "    # local copy: data/cik_to_name.json\n",
    "    cik_to_name = pd.read_json('https://www.sec.gov/files/company_tickers.json').transpose()\n",
    "    cik_to_name['ticker'] = cik_to_name.ticker.str.upper()\n",
    "    cik_to_name['cik'] = cik_to_name.cik_str.astype(str)\n",
    "    return cik_to_name\n",
    "\n",
    "def process_spac_lists(file_path_current, file_path_past, write=False):\n",
    "    # current spac list\n",
    "    spac_list_current = pd.read_csv(file_path_current)\n",
    "    spac_list_current = spac_list_current.Ticker.unique()\n",
    "    spac_list_current = pd.DataFrame(spac_list_current, columns=['Ticker'])\n",
    "    \n",
    "    # past spac list (completed business combination)\n",
    "    spac_list_past = pd.read_csv(file_path_past)\n",
    "    spac_list_past.fillna('missing', inplace=True)\n",
    "    spac_list_past['dupe_filter'] = spac_list_past['Old Ticker'] + spac_list_past['New Ticker']\n",
    "    spac_list_past = spac_list_past[spac_list_past.dupe_filter.isin(spac_list_past.dupe_filter.unique())]\n",
    "    spac_list_past.drop(columns=['dupe_filter'], inplace=True)\n",
    "    \n",
    "    # write to file\n",
    "    if write==True:\n",
    "        spac_list_current.to_csv('spac_list_current.csv', index=False)\n",
    "        spac_list_past.to_csv('spac_list_past.csv', index=False)\n",
    "    \n",
    "    # get ticker to cik and cik to company name file, then merge\n",
    "    ticker_to_cik = get_ticker_to_cik()\n",
    "    cik_to_name = get_cik_to_name()\n",
    "    spac_list_past = spac_list_past.merge(ticker_to_cik, how='left', left_on='New Ticker', right_on='ticker')\n",
    "    spac_list_past = spac_list_past.merge(cik_to_name[['cik','ticker','title']], how='left', on=['cik','ticker'])\n",
    "    spac_list_current = spac_list_current.merge(ticker_to_cik, how='left', left_on='Ticker', right_on='ticker')\n",
    "    spac_list_current = spac_list_current.merge(cik_to_name[['cik','ticker','title']], how='left', on=['cik','ticker'])\n",
    "    \n",
    "    return spac_list_current, spac_list_past\n",
    "\n",
    "def form_html_to_text(forms_html):\n",
    "    forms_text = []\n",
    "    for form_html in forms_html:\n",
    "        form_text = form_html.text_content().replace('\\n',' ').replace('\\xa0',' ').lower()\n",
    "        forms_text.append(form_text)\n",
    "    return forms_text\n",
    "\n",
    "def create_date_text_df(forms_text, form_type):\n",
    "    df = pd.DataFrame()\n",
    "    for form_text in forms_text:\n",
    "        try:\n",
    "            split_text = form_text.split('date of report (date of earliest event reported): ')[1].split(', ')\n",
    "            date_string = split_text[0].replace(' ','') + ', ' + split_text[1].replace(' ','')[0:4]\n",
    "            date_dt = dt.strptime(date_string, '%B%d, %Y')\n",
    "            date_dt = date_dt.strftime('%Y-%m-%d')\n",
    "            df = df.append(pd.Series([date_dt, form_type, form_text]), ignore_index=True)\n",
    "#             print(date_dt, 'form added')\n",
    "        except:\n",
    "            print('Logic to find date broke. See text:\\n', form_text)\n",
    "            raise Exception('Could not find date')\n",
    "    df.columns = ['date','form','text']\n",
    "    return df\n",
    "\n",
    "def get_forms_text(company_name, cik_id, form_type):\n",
    "    print(company_name)\n",
    "    company = Company(company_name, cik_id)\n",
    "    print('url to forms:', company.get_filings_url(filing_type=form_type, ownership='include', no_of_entries=100))\n",
    "    forms_site_html = company.get_all_filings(filing_type=form_type, ownership='include', no_of_entries=100)\n",
    "    forms_html = company.get_documents(forms_site_html, no_of_documents=100, debug=False)\n",
    "    forms_text = form_html_to_text(forms_html)\n",
    "    if len(forms_text)==0:\n",
    "        return\n",
    "    df = create_date_text_df(forms_text, form_type)\n",
    "    return df\n",
    "\n",
    "def simple_text_match(df_form, substring):\n",
    "    df_form[substring.replace(' ','_')+'_found'] = df_form.text.apply(lambda x: 1 if substring in x else 0)\n",
    "    return df_form\n",
    "\n",
    "def bulk_save_alphavantage_data(symbols, start_date='2018-01-01', end_date='2020-07-10'):\n",
    "    for symbol in symbols:\n",
    "        print(symbol)\n",
    "        df_prices = get_historical_prices(symbol=symbol,\n",
    "                                          start_date=start_date,\n",
    "                                          end_date=end_date,\n",
    "                                          source='alphavantage')\n",
    "        df_prices = process_historical_prices(df_prices)\n",
    "        df_prices.to_csv('data/prices/'+symbol+'_prices.csv', index=False)\n",
    "        time.sleep(12)\n",
    "        \n",
    "def load_saved_prices_data(symbol):\n",
    "    df_prices = pd.read_csv('data/prices/'+symbol+'_prices.csv')\n",
    "    print('price data min date:', df_prices.date.min())\n",
    "    print('price data max date:', df_prices.date.max())\n",
    "    return df_prices\n",
    "\n",
    "def get_historical_prices(symbol, start_date, end_date, source):\n",
    "    print('input start_date:', start_date)\n",
    "    print('input end_date:', end_date)\n",
    "    start_split = start_date.split('-')\n",
    "    end_split = end_date.split('-')\n",
    "    start = dt(int(start_split[0]), int(start_split[1]), int(start_split[2]))\n",
    "    end = dt(int(end_split[0]), int(end_split[1]), int(end_split[2]))\n",
    "    # be careful with missing/limited data in yahoo data\n",
    "    if source=='yahoo':\n",
    "        df_prices = pdr.data.DataReader(name=symbol, data_source='yahoo', start=start, end=end)\n",
    "    # alphavantage seems to be most reliable. 5 calls per minute and 500 calls per day\n",
    "    if source=='alphavantage':\n",
    "        df_prices = pdr.data.DataReader(name=symbol, data_source='av-daily', start=start, end=end,\n",
    "                                        api_key='BDB9WJQRCZKINCLD')\n",
    "    # iex has extremely limited api calls\n",
    "    if source=='iex':\n",
    "        df_prices = pdr.data.DataReader(name=symbol, data_source='iex', start=start, end=end,\n",
    "                                        api_key='pk_970dfff359894b15a056cf677c02e11f')\n",
    "    return df_prices\n",
    "\n",
    "def process_historical_prices(df_prices):\n",
    "    df_prices.reset_index(inplace=True)\n",
    "    df_prices.rename(columns={'index':'date'}, inplace=True)\n",
    "    df_prices.columns = df_prices.columns.str.lower()\n",
    "    df_prices['date'] = df_prices.date.astype(str)\n",
    "    df_prices['close_t+1'] = df_prices.close.shift(-1)\n",
    "    df_prices['close_t+3'] = df_prices.close.shift(-3)\n",
    "    df_prices['close_t+5'] = df_prices.close.shift(-5)\n",
    "    df_prices['close_t+7'] = df_prices.close.shift(-7)\n",
    "    df_prices['open_close_t+1_%chg'] = (df_prices['close_t+1'] - df_prices['open']) / df_prices['open']\n",
    "    df_prices['open_close_t+3_%chg'] = (df_prices['close_t+3'] - df_prices['open']) / df_prices['open']\n",
    "    df_prices['open_close_t+5_%chg'] = (df_prices['close_t+5'] - df_prices['open']) / df_prices['open']\n",
    "    df_prices['open_close_t+7_%chg'] = (df_prices['close_t+7'] - df_prices['open']) / df_prices['open']\n",
    "    df_prices = df_prices.round(2)\n",
    "    print('output min date:', df_prices.date.min())\n",
    "    print('output max date:', df_prices.date.max())\n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load current and past spac lists\n",
    "spac_list_current, spac_list_past = process_spac_lists(file_path_current='data/spac_list_current.csv',\n",
    "                                                       file_path_past='data/spac_list_past.csv',\n",
    "                                                       write=False)\n",
    "\n",
    "# spacs missing price data\n",
    "missing_past_spacs = ['missing', 'LCAH', 'FMCI1', 'CFCO']\n",
    "missing_current_spacs = ['ACNDU', 'ARYB', 'BRLI', 'DFHT', 'DMYD', 'FUSE', 'GOAC', 'IWAC', 'LCAH', 'LGVW',\n",
    "                         'MCAC', 'MLAC', 'PANA', 'PSAC', 'PSTH', 'SSMC', 'TREB']\n",
    "\n",
    "# bulk save price data for symbols in spac lists (due to API limits)\n",
    "# symbols_past_new_ticker = [x for x in spac_list_past.ticker.unique().tolist() if str(x)!='nan']\n",
    "# symbols_past_old_ticker = spac_list_past['Old Ticker'].unique().tolist()\n",
    "# symbols_past_old_ticker = [x for x in symbols_past_old_ticker if x not in missing_past_spacs]\n",
    "# symbols_current = [x for x in spac_list_current['Ticker'] if x not in missing_current_spacs]\n",
    "# bulk_save_alphavantage_data(symbols=symbols_past_new_ticker, start_date='2018-01-01', end_date='2020-07-10')\n",
    "# bulk_save_alphavantage_data(symbols=symbols_past_old_ticker, start_date='2018-01-01', end_date='2020-07-10')\n",
    "# bulk_save_alphavantage_data(symbols=symbols_current, start_date='2018-01-01', end_date='2020-07-10')\n",
    "\n",
    "# bad price data: ACEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ind in range(22, len(spac_list_past)):\n",
    "#     broken_inds_current = [2,5,10,16,22,33,38,39]\n",
    "#     if ind in broken_inds_current:\n",
    "#         continue\n",
    "    broken_inds_past = [10,14,16,17,22] # 22 is SPCE\n",
    "    if ind in broken_inds_past:\n",
    "        continue\n",
    "    \n",
    "    row = spac_list_past.iloc[ind]\n",
    "    print('index:', ind)\n",
    "    print(row.ticker)\n",
    "    \n",
    "    # get form 8Ks\n",
    "    df_form_8K = get_forms_text(company_name=row.title, cik_id=row.cik, form_type='8-K')\n",
    "    if df_form_8K is None:\n",
    "        print('no 8Ks found\\n')\n",
    "        continue\n",
    "    df_form_8K = simple_text_match(df_form_8K, 'letter of intent')\n",
    "    df_form_8K = simple_text_match(df_form_8K, 'business combination agreement')\n",
    "\n",
    "    # get stock prices\n",
    "    try:\n",
    "        df_prices = load_saved_prices_data(row.ticker)\n",
    "    except:\n",
    "        df_prices = get_historical_prices(symbol=row.ticker,\n",
    "                                          start_date=df_form_8K.date.min(),\n",
    "                                          end_date=(dt.strptime(df_form_8K.date.max(),'%Y-%m-%d') + \n",
    "                                                    timedelta(days=5)).strftime('%Y-%m-%d'),\n",
    "                                          source='alphavantage')\n",
    "        df_price = process_historical_prices(df_prices)\n",
    "\n",
    "    # output returns per form\n",
    "    df_returns = df_form_8K.merge(df_prices[['date','open_close_t+1_%chg','open_close_t+3_%chg']],\n",
    "                                  how='left', on='date')\n",
    "    display(df_returns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
